{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wrapped-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy pandas matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import for Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# import for Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# imports for Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats \n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "center-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for printing with underline, colors and bold\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58e02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders\n",
    "directory = \"Decision Tree\"\n",
    "parent_dir = \"./\"\n",
    "path = os.path.join(parent_dir, directory)\n",
    "if not os.path.exists(directory): \n",
    "    os.mkdir(path)\n",
    "    \n",
    "directory = \"Best Params\"\n",
    "parent_dir = \"./\"\n",
    "path = os.path.join(parent_dir, directory)\n",
    "if not os.path.exists(directory): \n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761767ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file\n",
    "df = pd.read_csv(\"./csv files/marketing_campaigns_train_after_pre_proc.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a10462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifier = df.copy()\n",
    "l = ['age', 'account_balance', 'n_contact', 'p_days','l_call_duration','n_p_contact','p_days','status_cat','education_cat',\n",
    "    'profession_cat', 'device_cat', 'month_l_date_cat', 'p_outcome_cat','age_bin','account_balance_bin',\n",
    "    'education_Pre_Proc_cat','profession_Pre_Proc_cat','device_Pre_Proc_cat', 'p_outcome_Pre_Proc_cat']\n",
    "\n",
    "df_classifier.drop(l, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bec6f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30517 entries, 512491 to 516748\n",
      "Data columns (total 18 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   loan                             30517 non-null  int64  \n",
      " 1   mortgage                         30517 non-null  int64  \n",
      " 2   credit                           30517 non-null  int64  \n",
      " 3   positive                         30517 non-null  int64  \n",
      " 4   isEmployed_cat                   30517 non-null  int64  \n",
      " 5   age_min_max                      30517 non-null  float64\n",
      " 6   n_p_contact_min_max              30517 non-null  float64\n",
      " 7   p_days_min_max                   30517 non-null  float64\n",
      " 8   n_contact_min_max                30517 non-null  float64\n",
      " 9   account_balance_min_max          30517 non-null  float64\n",
      " 10  l_call_duration_min_max          30517 non-null  float64\n",
      " 11  status_cat_min_max               30517 non-null  float64\n",
      " 12  education_Pre_Proc_cat_min_max   30517 non-null  float64\n",
      " 13  profession_Pre_Proc_cat_min_max  30517 non-null  float64\n",
      " 14  device_Pre_Proc_cat_min_max      30517 non-null  int64  \n",
      " 15  month_l_date_cat_min_max         30517 non-null  float64\n",
      " 16  p_outcome_Pre_Proc_cat_min_max   30517 non-null  float64\n",
      " 17  subscribed                       30517 non-null  int64  \n",
      "dtypes: float64(11), int64(7)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_classifier.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d16af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to features and target\n",
    "X = df_classifier.drop('subscribed', axis=1)\n",
    "y = df_classifier['subscribed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "passing-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-tomorrow",
   "metadata": {},
   "source": [
    "# <font color = 'red'> Decision Tree </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file Best_DT \n",
    "f_r = open(\"./Best Params/Best_DT.txt\", \"r\")\n",
    "Lines = f_r.read().splitlines()\n",
    "f_r.close()\n",
    "best_DT = []\n",
    "for line in Lines:\n",
    "    best_DT.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-discretion",
   "metadata": {},
   "source": [
    "### Find the hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa2a56",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(splitter='best',random_state=42)\n",
    "\n",
    "criterion= ['gini','entropy']\n",
    "\n",
    "max_depth = [k for k in range(2,50)]\n",
    "\n",
    "min_samples_split = [2,3,4,10,50,100,150,200,250,300,350,400]\n",
    "\n",
    "min_samples_leaf = [2,3,4,10,50,100,150,200,250,300,350,400]\n",
    "\n",
    "random_grid = {\n",
    "               'criterion': criterion, \n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "dt_random = RandomizedSearchCV(estimator = dt, param_distributions = random_grid, n_iter = 200,cv = 10,\n",
    "                               verbose = 2, random_state = 42, n_jobs = -1)\n",
    "dt_random.fit(X_train, y_train)\n",
    "parameters = dt_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef9fce",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(splitter='best',random_state=42)\n",
    "criterion = [parameters['criterion']]\n",
    "\n",
    "if parameters['max_depth'] > 2 :\n",
    "    max_depth = [parameters['max_depth'] - 1 , parameters['max_depth'], parameters['max_depth'] + 2,parameters['max_depth']+3]\n",
    "else:\n",
    "    max_depth = [parameters['max_depth'], parameters['max_depth'] + 2,parameters['max_depth']+3]\n",
    "\n",
    "\n",
    "min_samples_split = [parameters['min_samples_split'],parameters['min_samples_split']+1,parameters['min_samples_split']+2,\n",
    "                    parameters['min_samples_split']+3]\n",
    "\n",
    "min_samples_leaf = [parameters['min_samples_leaf'],parameters['min_samples_leaf']+1,parameters['min_samples_leaf']+2,\n",
    "                   parameters['min_samples_leaf']+3]\n",
    "\n",
    "param_grid = {\n",
    "               'criterion': criterion, \n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "dt_grid_search = GridSearchCV(estimator = dt, param_grid = param_grid, cv = 10, n_jobs = -1, verbose = 2, scoring = 'accuracy')\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "parameters_dt = dt_grid_search.best_params_\n",
    "parameters_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc39e8c",
   "metadata": {},
   "source": [
    "#### Save the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = round((dt_grid_search.best_score_)*100,2)\n",
    "print(bcolors.OKCYAN + 'accuracy after that train:'+ bcolors.ENDC + \" \", accuracy ,\"%\")\n",
    "if accuracy > float(best_DT[0]):\n",
    "    f_w = open(\"./Best Params/Best_DT.txt\", \"w\")\n",
    "    f_w.write(str(accuracy)+'\\n')\n",
    "    f_w.write(str(parameters_dt['criterion']) + '\\n')\n",
    "    f_w.write(str(parameters_dt['max_depth']) + '\\n')\n",
    "    f_w.write(str(parameters_dt['min_samples_split']) + '\\n')\n",
    "    f_w.write(str(parameters_dt['min_samples_leaf']))\n",
    "    f_w.close()\n",
    "\n",
    "else:\n",
    "    accuracy = float(best_DT[0])\n",
    "    parameters_dt['criterion'] = best_DT[1]\n",
    "    parameters_dt['max_depth'] = int(best_DT[2])\n",
    "    parameters_dt['min_samples_split'] = int(best_DT[3])\n",
    "    parameters_dt['min_samples_leaf'] = int(best_DT[4])\n",
    "\n",
    "    \n",
    "dt = DecisionTreeClassifier(criterion=parameters_dt['criterion'], splitter='best', \n",
    "                          max_depth=parameters_dt['max_depth'], min_samples_split=parameters_dt['min_samples_split'],\n",
    "                            min_samples_leaf=parameters_dt['min_samples_leaf'], random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-letters",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-budapest",
   "metadata": {},
   "source": [
    "#### Printing Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = export_graphviz(dt, filled=True, rounded=True, \n",
    "                    special_characters=True,feature_names = X.columns,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot)\n",
    "graph.write_png('./Decision Tree/theTree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-natural",
   "metadata": {},
   "source": [
    "#### Check Accuracy VS max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = dt_grid_search.cv_results_['mean_test_score']\n",
    "param_values = list(dt_grid_search.cv_results_['param_max_depth'])\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(param_values, test_scores, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Accuracy Rate VS max_depth')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-couple",
   "metadata": {},
   "source": [
    "# <font color = 'red'> Random Forest </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file Best_RF \n",
    "f_r = open(\"./Best Params/Best_RF.txt\", \"r\")\n",
    "Lines = f_r.read().splitlines()\n",
    "f_r.close()\n",
    "best_RF = []\n",
    "for line in Lines:\n",
    "    best_RF.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2508314",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 42)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "\n",
    "max_features = ['auto', 'log2', 2, 5, 8]\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(5, 50, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [1, 2, 5, 10, 15, 20]\n",
    "\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "max_samples = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_samples': max_samples}\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 200, cv = 10,\n",
    "                               verbose = 2, random_state = 42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c121051",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_RF = rf_random.best_params_\n",
    "\n",
    "n_estimators = [parameters_RF['n_estimators']]\n",
    "\n",
    "max_features = [parameters_RF['max_features']]\n",
    "\n",
    "if parameters_RF['max_depth'] != None :\n",
    "    max_depth = [parameters_RF['max_depth'], parameters_RF['max_depth'] + 1, parameters_RF['max_depth'] + 2]\n",
    "else:\n",
    "    max_depth = [None]    \n",
    "\n",
    "min_samples_split = [parameters_RF['min_samples_split'] ,parameters_RF['min_samples_split']+1,\n",
    "                     parameters_RF['min_samples_split']+2]\n",
    "\n",
    "min_samples_leaf = [parameters_RF['min_samples_leaf'],parameters_RF['min_samples_leaf']+1,\n",
    "                    parameters_RF['min_samples_leaf']+2]\n",
    "\n",
    "max_samples = [parameters_RF['max_samples'],parameters_RF['max_samples']+0.1,parameters_RF['max_samples']+0.2]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_samples': max_samples}\n",
    "grid_search_RF = GridSearchCV(estimator = rf, param_grid = random_grid , cv = 10, n_jobs = -1, verbose = 2,scoring='accuracy')\n",
    "grid_search_RF.fit(X_train, y_train)\n",
    "grid_search_RF.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc96508",
   "metadata": {},
   "source": [
    "#### Save the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_RF = grid_search_RF.best_params_\n",
    "rf_accuracy = grid_search_RF.best_score_\n",
    "accuracy = round(rf_accuracy*100,2)\n",
    "print(bcolors.OKCYAN + 'accuracy after that train:'+ bcolors.ENDC + \" \", accuracy ,\"%\")\n",
    "if accuracy > float(best_RF[0]):\n",
    "    f_w = open(\"./Best Params/Best_RF.txt\", \"w\")\n",
    "    f_w.write(str(accuracy)+'\\n')\n",
    "    f_w.write(str(parameters_RF['max_depth']) + '\\n')\n",
    "    f_w.write(str(parameters_RF['max_features']) + '\\n')\n",
    "    f_w.write(str(parameters_RF['max_samples']) + '\\n')\n",
    "    f_w.write(str(parameters_RF['min_samples_leaf']))\n",
    "    f_w.write(str(parameters_RF['min_samples_split']))\n",
    "    f_w.write(str(parameters_RF['n_estimators']))\n",
    "    f_w.close()\n",
    "\n",
    "else:\n",
    "    accuracy = float(best_RF[0])\n",
    "    parameters_RF['max_depth'] = int(best_RF[1])\n",
    "    parameters_RF['max_features'] = int(best_RF[2])\n",
    "    parameters_RF['max_samples'] = float(best_RF[3])\n",
    "    parameters_RF['min_samples_leaf'] = int(best_RF[4])\n",
    "    parameters_RF['min_samples_split'] = int(best_RF[5])\n",
    "    parameters_RF['n_estimators'] = int(best_RF[6])\n",
    "\n",
    "    \n",
    "rf = RandomForestClassifier(max_depth = parameters_RF['max_depth'],max_features = parameters_RF['max_features'],\n",
    "                            max_samples=parameters_RF['max_samples'] ,min_samples_leaf= parameters_RF['min_samples_leaf'],\n",
    "                            min_samples_split= parameters_RF['min_samples_split'],n_estimators= parameters_RF['n_estimators'],\n",
    "                            random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-object",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-chase",
   "metadata": {},
   "source": [
    "#### Check Accuracy VS Number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_trees = {'n_estimators': [int(x) for x in np.linspace(1, 601, 60)]}\n",
    "\n",
    "rf_check_grid_numTrees = GridSearchCV(estimator = rf, param_grid=num_of_trees, verbose = 2, n_jobs=-1, cv = 10,\n",
    "                                scoring = 'accuracy')\n",
    "rf_check_grid_numTrees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = rf_check_grid_numTrees.cv_results_['mean_test_score']\n",
    "param_values = list(rf_check_grid_numTrees.cv_results_['param_n_estimators'])\n",
    "plt.subplots(1, figsize=(10, 6))\n",
    "plt.subplot(121)\n",
    "plt.plot(param_values, test_scores, 'bo-', label = 'test')\n",
    "plt.xlabel('Num trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy VS Number of Trees' )\n",
    "plt.tight_layout(pad = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-power",
   "metadata": {},
   "source": [
    "# <font color = 'red'> SVM </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opened-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file Best_SVM \n",
    "f_r = open(\"./Best Params/Best_SVM.txt\", \"r\")\n",
    "Lines = f_r.read().splitlines()\n",
    "f_r.close()\n",
    "best_SVM = []\n",
    "for line in Lines:\n",
    "    best_SVM.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f4d95",
   "metadata": {},
   "source": [
    "### Find the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893374c7",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-circulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 81 is smaller than n_iter=200. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n"
     ]
    }
   ],
   "source": [
    "SVM_random = svm.SVC(probability=True)\n",
    "\n",
    "random_grid = {'base_estimator__C': [0.1, 1, 10],\n",
    "               'base_estimator__gamma': [1, 0.1, 0.01],\n",
    "               'base_estimator__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "               'base_estimator__degree':[k for k in range(3,6)]\n",
    "              }\n",
    "n_estimators = 10\n",
    "SVM_random = BaggingClassifier(base_estimator=SVC(probability=True), max_samples=1.0 / n_estimators, n_estimators=n_estimators)\n",
    "SVM_random = RandomizedSearchCV(estimator = SVM_random, param_distributions = random_grid, n_iter = 200,cv = 10,\n",
    "                               verbose = 2, random_state = 42, n_jobs = -1)\n",
    "SVM_random.fit(X_train, y_train)\n",
    "parameters = SVM_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dca734",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid_search = svm.SVC(probability=True)\n",
    "\n",
    "param_grid = {'base_estimator__C': [parameters['base_estimator__C']/10, parameters['base_estimator__C']*10, parameters['base_estimator__C']],\n",
    "              'base_estimator__gamma': [parameters['base_estimator__gamma'], parameters['base_estimator__gamma']/10, parameters['base_estimator__gamma']*10],\n",
    "              'base_estimator__kernel': [parameters['base_estimator__kernel']],\n",
    "              'base_estimator__degree':[parameters['base_estimator__degree'], parameters['base_estimator__degree'] + 1, parameters['base_estimator__degree'] - 1]\n",
    "             }\n",
    "svm_grid_search = BaggingClassifier(base_estimator=SVC(probability=True), max_samples=1.0 / n_estimators, n_estimators=n_estimators)\n",
    "svm_grid_search = GridSearchCV(estimator = svm_grid_search, param_grid = param_grid, cv = 10, n_jobs = -1,\n",
    "                               verbose = 2, scoring = 'accuracy')\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "parameters_SVM = svm_grid_search.best_params_\n",
    "accuracy = round(svm_grid_search.best_score_*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0121eb",
   "metadata": {},
   "source": [
    "#### Save the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bcolors.OKCYAN + 'accuracy after that train:'+ bcolors.ENDC + \" \", accuracy ,\"%\")\n",
    "if accuracy > float(best_SVM[0]):\n",
    "    f_w = open(\"./Best Params/Best_SVM.txt\", \"w\")\n",
    "    f_w.write(str(accuracy)+'\\n')\n",
    "    f_w.write(str(parameters_SVM['base_estimator__C']) + '\\n')\n",
    "    f_w.write(str(parameters_SVM['base_estimator__gamma']) + '\\n')\n",
    "    f_w.write(str(parameters_SVM['base_estimator__kernel']) + '\\n')\n",
    "    f_w.write(str(parameters_SVM['base_estimator__degree']) + '\\n')\n",
    "    f_w.close()\n",
    "\n",
    "else:\n",
    "    accuracy = float(best_SVM[0])\n",
    "    parameters_SVM['base_estimator__C'] = float(best_SVM[1])\n",
    "    parameters_SVM['base_estimator__gamma'] = float(best_SVM[2])\n",
    "    parameters_SVM['base_estimator__kernel'] = str(best_SVM[3])\n",
    "    parameters_SVM['base_estimator__degree'] = int(best_SVM[4])\n",
    "    \n",
    "SVM = svm.SVC(kernel=parameters_SVM['base_estimator__kernel'], C=parameters_SVM['base_estimator__C'], gamma = parameters_SVM['base_estimator__gamma'],\n",
    "                       degree = parameters_SVM['base_estimator__degree'], probability=True)\n",
    "\n",
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-stupid",
   "metadata": {},
   "source": [
    "# <font color = 'red'> K-Nearest Neighbors </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d622946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file Best_KNN \n",
    "f_r = open(\"./Best Params/Best_KNN.txt\", \"r\")\n",
    "Lines = f_r.read().splitlines()\n",
    "f_r.close()\n",
    "best_KNN = []\n",
    "for line in Lines:\n",
    "    best_KNN.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85549f8",
   "metadata": {},
   "source": [
    "### Find the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3e3ef",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "n_neighbors = [i for i in range(5,40)]\n",
    "random_grid = {'n_neighbors' : n_neighbors}\n",
    "KNN_random = RandomizedSearchCV(estimator = KNN, param_distributions = random_grid, n_iter = 200,cv = 10,\n",
    "                               verbose = 2, random_state = 42, n_jobs = -1)\n",
    "KNN_random.fit(X_train, y_train)\n",
    "parameters = KNN_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d32c7",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [parameters['n_neighbors'] - 1 ,parameters['n_neighbors'],parameters['n_neighbors'] + 1]\n",
    "param_grid = {'n_neighbors' : n_neighbors}\n",
    "KNN_grid_search = GridSearchCV(estimator = KNN, param_grid = param_grid, cv = 10, n_jobs = -1, verbose = 2, scoring = 'accuracy')\n",
    "KNN_grid_search.fit(X_train, y_train)\n",
    "parameters_KNN = KNN_grid_search.best_params_\n",
    "accuracy = round(KNN_grid_search.best_score_*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d50c5",
   "metadata": {},
   "source": [
    "#### Save the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy after that train =' + ' '+ str(accuracy)+\"%\")\n",
    "if accuracy > float(best_KNN[0]):\n",
    "    f_w = open(\"./Best Params/Best_KNN.txt\", \"w\")\n",
    "    f_w.write(str(accuracy)+'\\n')\n",
    "    f_w.write(str(parameters_KNN['n_neighbors']) + '\\n')\n",
    "    f_w.close()\n",
    "\n",
    "else:\n",
    "    accuracy = float(best_KNN[0])\n",
    "    parameters_KNN['n_neighbors'] = int(best_KNN[1])\n",
    "    \n",
    "KNN = KNeighborsClassifier(n_neighbors = parameters_KNN['n_neighbors'])\n",
    "\n",
    "\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-costa",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(X_train, y_train, test_size=0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_temp, y_train_temp)\n",
    "    pred_i = knn.predict(X_test_temp)\n",
    "    a = metrics.accuracy_score(y_test_temp, pred_i)\n",
    "    acc.append(round(a*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(5,40), acc, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Accuracy Rate VS K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-glucose",
   "metadata": {},
   "source": [
    "# <font color = 'red'> Naive Bayes classifier </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB = GaussianNB()\n",
    "MNB = MultinomialNB()\n",
    "COPNB = ComplementNB()\n",
    "BNB = BernoulliNB()\n",
    "\n",
    "GNB.fit(X_train, y_train)\n",
    "MNB.fit(X_train, y_train)\n",
    "BNB.fit(X_train, y_train)\n",
    "COPNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-roulette",
   "metadata": {},
   "source": [
    "# <font color = 'red'> Find the best classifier </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-destruction",
   "metadata": {},
   "source": [
    "### Comparison between best classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Fold\n",
    "clf_list = [dt,rf,SVM,KNN,GNB,MNB,COPNB,BNB]\n",
    "cm_dict, auc_dict = {}, {}\n",
    "X_train_npy = X_train.to_numpy()\n",
    "y_train_npy = y_train.to_numpy()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42) #for cross validation\n",
    "k = 0\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    k+=1\n",
    "    print(bcolors.HEADER + bcolors.BOLD + '_____________________________________',k,'_____________________________________'\n",
    "          + bcolors.ENDC)\n",
    "    print(\"\")\n",
    "    # split to train and test\n",
    "    X_train_KF, X_test_KF = X_train_npy[train_index], X_train_npy[test_index]\n",
    "    y_train_KF, y_test_KF = y_train_npy[train_index], y_train_npy[test_index]\n",
    "    \n",
    "    for clf in clf_list:\n",
    "        # train the model and make a prediction\n",
    "        clf.fit(X_train_KF,y_train_KF)\n",
    "        y_pred = clf.predict(X_test_KF)\n",
    "        cm = metrics.confusion_matrix(y_test_KF, y_pred)\n",
    "        \n",
    "        y_probs = clf.predict_proba(X_test_KF) # probability prediction\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test_KF, y_probs[:,1])\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        \n",
    "        # save the results\n",
    "        cm_list = cm_dict.get(clf,[])\n",
    "        cm_list.append(cm)\n",
    "        cm_dict[clf] = cm_list\n",
    "        \n",
    "        auc_list = auc_dict.get(clf,[])\n",
    "        auc_list.append(auc)\n",
    "        auc_dict[clf] = auc_list\n",
    "        \n",
    "        # print the results\n",
    "        print(bcolors.UNDERLINE + bcolors.OKCYAN + \"Classifier:\" + bcolors.ENDC + \" \"  , clf)\n",
    "        print(bcolors.UNDERLINE + bcolors.OKCYAN + \"Accuracy:\" + bcolors.ENDC + \" \" ,\n",
    "              round((metrics.accuracy_score(y_test_KF, y_pred))*100,2),\"%\")\n",
    "        print(bcolors.UNDERLINE + bcolors.OKCYAN + \"Confusion matrix:\" + bcolors.ENDC)\n",
    "        display(pd.DataFrame(cm))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-testing",
   "metadata": {},
   "source": [
    "### Print average results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict = {}\n",
    "sen_dict = {}\n",
    "spec_dict={}\n",
    "prec_dict = {}\n",
    "k = 0\n",
    "Best_clf = 0\n",
    "Best_acc = 0\n",
    "for clf in clf_list:\n",
    "    k+=1\n",
    "    acc = [(cm[0][0]+cm[1][1])/sum(sum(cm)) for cm in cm_dict[clf]]\n",
    "    acc_dict[clf] = acc\n",
    "    m_acc = np.mean(acc)\n",
    "    sensitivity = [(cm[1][1])/(cm[1][1]+cm[1][0]) for cm in cm_dict[clf]]\n",
    "    specifity = [(cm[0][0])/(cm[0][0]+cm[0][1]) for cm in cm_dict[clf]]\n",
    "    precision = [(cm[1][1])/(cm[1][1]+cm[0][1]) for cm in cm_dict[clf]]\n",
    "    sen_dict[clf] = sensitivity\n",
    "    spec_dict[clf] = specifity\n",
    "    prec_dict[clf] = precision\n",
    "    m_auc = np.mean(auc_dict[clf])\n",
    "    m_p = np.mean(precision)\n",
    "    m_sen = np.mean(sensitivity)\n",
    "    m_spec = np.mean(specifity)\n",
    "    \n",
    "    # Get the best clf\n",
    "    if m_acc > Best_acc:\n",
    "        Best_acc = m_acc\n",
    "        Best_clf = clf\n",
    "\n",
    "    # Print the result\n",
    "    print(bcolors.HEADER + bcolors.BOLD + '_____________________________________' + \" Classifier:\",k,\n",
    "          '_____________________________________' + bcolors.ENDC)\n",
    "    print(\"\")\n",
    "    print(bcolors.UNDERLINE + bcolors.OKCYAN + \"Classifier:\" + bcolors.ENDC + \" \"  , clf)\n",
    "    print(bcolors.UNDERLINE + bcolors.OKCYAN + \"mean accuracy:\" + bcolors.ENDC + \" \" , round(m_acc*100,2))\n",
    "    print(bcolors.UNDERLINE + bcolors.OKCYAN + \"mean sensitivity:\" + bcolors.ENDC + \" \" , round(m_sen*100,2))\n",
    "    print(bcolors.UNDERLINE + bcolors.OKCYAN + \"mean specifity:\" + bcolors.ENDC + \" \" , round(m_spec*100,2))\n",
    "    print(bcolors.UNDERLINE + bcolors.OKCYAN + \"mean precision:\" + bcolors.ENDC + \" \" , round(m_p*100,2))\n",
    "    print(bcolors.UNDERLINE + bcolors.OKCYAN + \"mean AUC:\" + bcolors.ENDC + \" \" , round(m_auc*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-identity",
   "metadata": {},
   "source": [
    "### Print the best classifier we found: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-gender",
   "metadata": {},
   "source": [
    "### ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list.remove(Best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in clf_list:\n",
    "    print(bcolors.HEADER + bcolors.BOLD +'Best clf VS',c,bcolors.ENDC)\n",
    "    ttest,pval = stats.ttest_rel(acc_dict[Best_clf], acc_dict[c])\n",
    "    print(\"p-value:\" , pval)\n",
    "    if pval<0.05:\n",
    "        print(\"reject null hypothesis\")\n",
    "    else:\n",
    "        print(\"accept null hypothesis\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-addition",
   "metadata": {},
   "source": [
    "# Test the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Best_clf.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(bcolors.OKCYAN + 'confusion matrix:'+ bcolors.ENDC)\n",
    "cm = pd.DataFrame(metrics.confusion_matrix(y_test,y_pred))\n",
    "display(pd.DataFrame(cm))\n",
    "print(bcolors.OKCYAN + 'accuracy:'+bcolors.ENDC + \" \"\n",
    "      ,round(((cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]))*100,2))\n",
    "print(bcolors.OKCYAN + 'sensitivity:'+bcolors.ENDC + \" \"\n",
    "      ,round(((cm[1][1])/(cm[1][1]+cm[1][0]))*100,2))\n",
    "print(bcolors.OKCYAN + 'specificity:'+bcolors.ENDC + \" \"\n",
    "      ,round(((cm[0][0])/(cm[0][0]+cm[0][1]))*100,2))\n",
    "print(bcolors.OKCYAN + 'precision:'+bcolors.ENDC + \" \"\n",
    "      ,round(((cm[1][1])/(cm[1][1]+cm[0][1]))*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-bryan",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_b = Best_clf.predict_proba(X_test)\n",
    "fpr_b, tpr_b, _ = metrics.roc_curve(y_test, y_probs_b[:,1])\n",
    "auc_b = metrics.auc(fpr_b, tpr_b)\n",
    "plt.figure()\n",
    "plt.plot(fpr_b, tpr_b, color='darkorange', label='ROC curve (area = %0.2f)' %  auc_b)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with all the data\n",
    "Best_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-essex",
   "metadata": {},
   "source": [
    "# <font color = 'red'> Classify the test file </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test file\n",
    "df_test = pd.read_csv(\"./csv files/marketing_campaigns_test.csv\", index_col=0)\n",
    "df_test_after_PreProc = pd.read_csv(\"./csv files/marketing_campaigns_test_after_pre_proc.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifier_test = df_test_after_PreProc.copy()\n",
    "l = ['age', 'account_balance', 'n_contact', 'p_days','l_call_duration','n_p_contact','p_days','status_cat','education_cat',\n",
    "    'profession_cat', 'device_cat', 'month_l_date_cat', 'p_outcome_cat','age_bin','account_balance_bin',\n",
    "    'education_Pre_Proc_cat','profession_Pre_Proc_cat','device_Pre_Proc_cat', 'p_outcome_Pre_Proc_cat']\n",
    "\n",
    "df_classifier_test.drop(l, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifier_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Best_clf.predict(df_classifier_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['subscribed'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"marketing_campaigns_test_classifier_answers.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
